{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the Log likelihood and the gradient function for the Logistic Regression\n",
    "\n",
    "This is used to optimize the function using various techniques you may find in my other codes in the repo.\n",
    "\n",
    "08/27 - Created with iPython Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import math\n",
    "%load_ext Cython\n",
    "# n,x,y,xb\n",
    "n = 10\n",
    "beta = [-2,0.5]\n",
    "x = np.random.binomial(1,0.5,size=n)\n",
    "for i in range(len(x)):\n",
    "    y = np.random.binomial(1,1/(1+math.exp(-beta[0]-x[i]*beta[1])),size=n)\n",
    "xb = beta[0]+x*beta[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Likelihood computation - Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_likelihood(y,x,xb):    \n",
    "    ll = 0.0\n",
    "    for j in range(0,len(y)):\n",
    "        ll = ll + y[j]*xb[j] - math.log(1 + math.exp(xb[j]))\n",
    "    return ll\n",
    "%timeit log_likelihood(y,x,xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Function computation - Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grad_fn(y,x,xb):\n",
    "    l1 = 0.0\n",
    "    l2 = 0.0\n",
    "    for k in range(0,len(x)):\n",
    "        l1 = l1 + y[k] - math.exp(xb[k])/(1+math.exp(xb[k]))\n",
    "        l2 = l2 + x[k]*y[k] - x[k]*math.exp(xb[k])/(1+math.exp(xb[k]))\n",
    "    return [l1,l2]\n",
    "%timeit grad_fn(y,x,xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Log Likelihood computation - Cython(Cpp) implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.math cimport log,exp\n",
    "cpdef float log_likelihood_cpp(np.ndarray[long,ndim=1,mode='c'] y,np.ndarray[long,ndim=1,mode='c'] x,np.ndarray[double,ndim=1,mode='c'] xb):    \n",
    "    cdef float ll = 0.0\n",
    "    cdef int count,j = 0\n",
    "    count = x.shape[0]\n",
    "    for j from 0<=j<count:\n",
    "        ll += ((y[j])*(xb[j])) - (log(1 + exp(xb[j])))\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Gradient Function computation - Cython(Cpp) implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.math cimport log,exp\n",
    "cpdef np.ndarray[np.float] grad_fn_cpp(np.ndarray[long,ndim=1,mode='c'] y,np.ndarray[long,ndim=1,mode='c'] x,np.ndarray[double,ndim=1,mode='c'] xb):    \n",
    "    cdef float l1 = 0.0,l2 = 0.0\n",
    "    cdef int count,k = 0\n",
    "    cdef np.ndarray[np.double_t, ndim=1, mode=\"c\"] Y \n",
    "    count = x.shape[0]\n",
    "    for k from 0<=k<count:\n",
    "        l1 += (y[k]) - exp(xb[k])/(1+exp(xb[k]))\n",
    "        l2 += (x[k]*y[k]) - (x[k]*exp(xb[k])/(1+exp(xb[k])))\n",
    "    Y = np.array([l1,l2])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Log Likehood Function:\n",
    "\n",
    "Python\n",
    "%timeit log_likelihood(y,x,xb) # 10000 loops, best of 3: 71 µs per loop\n",
    "Cython\n",
    "%timeit log_likelihood_cpp(y,x,xb) # 100000 loops, best of 3: 3.49 µs per loop\n",
    "\n",
    "The Gradient Function:\n",
    "\n",
    "Python\n",
    "%timeit grad_fn(y,x,xb) # 10000 loops, best of 3: 106 µs per loop\n",
    "Cython\n",
    "%timeit grad_fn_cpp(y,x,xb) # 100000 loops, best of 3: 6.75 µs per loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "grad_fn_cpp(y,x,xb) #array([-1.50814223, -0.91212755])\n",
    "grad_fn(y,x,xb) #[-1.5081422291423694, -0.91212761903178163]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "log_likelihood(y,x,xb) #-1.6417064451286256\n",
    "log_likelihood_cpp(y,x,xb) #-1.6417064451286256"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
